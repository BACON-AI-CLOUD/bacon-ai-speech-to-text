<p align="center">
  <img src="assets/product-logo.png" alt="BACON-AI Speech-to-Text" width="280" />
</p>

<h1 align="center">BACON-AI Speech-to-Text</h1>

<p align="center">
  <strong>Free, private, local speech-to-text for AI chatbots and CLI tools</strong>
</p>

<p align="center">
  <a href="#features">Features</a> &bull;
  <a href="#how-it-works">How It Works</a> &bull;
  <a href="#installation">Installation</a> &bull;
  <a href="#usage-with-ai-tools">Usage with AI Tools</a> &bull;
  <a href="#roadmap">Roadmap</a> &bull;
  <a href="#coming-soon">Coming Soon</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License" />
  <img src="https://img.shields.io/badge/whisper-local--GPU-green.svg" alt="Whisper" />
  <img src="https://img.shields.io/badge/cost-FREE-brightgreen.svg" alt="Free" />
  <img src="https://img.shields.io/badge/privacy-100%25%20local-orange.svg" alt="Privacy" />
  <img src="https://img.shields.io/badge/version-1.5-blue.svg" alt="v1.5" />
  <img src="https://img.shields.io/badge/status-ALPHA-red.svg" alt="Alpha" />
</p>

> **Note:** This is the open-source community edition. A professional edition with advanced features is in development â€” see [Coming Soon](#coming-soon) below.

---

## What is BACON-AI Speech-to-Text?

BACON-AI Speech-to-Text is a local, private speech-to-text platform that integrates seamlessly with AI development tools like Claude Code, ChatGPT, Cursor, and more.

**Speak naturally. Get clean text. Inject it anywhere.**

No cloud. No subscription. No audio leaving your machine.

---

## Features

| Feature | Status |
|---------|--------|
| Live microphone transcription (Whisper, local GPU) | âœ… |
| Push-to-talk / Voice activation / Toggle modes | âœ… |
| Whisper model selector (tiny â†’ large-v3) | âœ… |
| AI text refinement (remove filler words, reformat) | âœ… |
| 6 AI providers: Ollama, Groq, OpenAI, Anthropic, Gemini, Claude CLI | âœ… |
| 12 prompt templates (Speech Cleanup, Technical Docs, Email, WhatsApp...) | âœ… |
| Type transcription to any window (Target Window) | âœ… |
| WebSocket bridge to Claude Code | âœ… |
| File transcription (audio/video files) | âœ… |
| YouTube & URL transcription | âœ… |
| Text Editor tab (load PDF/DOCX, edit, refine) | âœ… |
| Elisabeth voice assistant (discuss mode) | âœ… |
| History sidebar | âœ… |
| System tray icon (AHK) | âœ… |

---

## How It Works

```
Microphone â†’ Faster-Whisper (local) â†’ AI Refiner (optional) â†’ Clipboard / Target Window / Claude Code
```

1. **Record** with push-to-talk, voice activation, or toggle button
2. **Transcribe** locally using Faster-Whisper (runs entirely on your machine)
3. **Refine** with AI to remove filler words and improve formatting
4. **Output** by typing to any window, copying, or injecting into Claude Code

---

## Installation

### Prerequisites

- Python 3.10+ with `uv`
- Node.js 18+ with npm
- NVIDIA GPU (optional but recommended)

### Quick Start

```bash
git clone https://github.com/BACON-AI-CLOUD/bacon-ai-speech-to-text.git
cd bacon-ai-speech-to-text

# Start frontend + backend
./start-dev.sh       # Linux / WSL2
start-dev.bat        # Windows

# Open in browser: http://localhost:5002
```

---

## Usage with AI Tools

### Claude Code
The WebSocket bridge injects transcribed text directly into your active Claude Code session. Hold your hotkey, dictate, and your words appear in Claude Code â€” hands-free.

### Any AI Browser Tab
Use the Target Window feature to type transcribed text into any browser tab or application window â€” ChatGPT, Gemini, Cursor, VS Code, Word, Outlook.

### File Transcription
Drag any audio/video file (or paste a YouTube URL) onto the File tab to get a full transcript â€” then refine, edit, and export it.

---

## Privacy

- Raw audio **never leaves your machine**
- Whisper transcription runs entirely on your local GPU/CPU
- Cloud AI providers (optional) receive **text only**, never audio
- API keys stored in `~/.config/bacon-ai-voice/.env`, never in the repo

---

## Roadmap

| Version | Status | Highlights |
|---------|--------|-----------|
| v1.0 | âœ… Released | Core STT, 3 activation modes, WebSocket bridge |
| v1.1 | âœ… Released | AI Refiner, Groq + Ollama + Gemini |
| v1.2 | âœ… Released | OpenAI + Anthropic + Claude CLI, discuss mode |
| v1.3 | âœ… Released | File transcription, system tray, hotkeys |
| v1.4 | âœ… Released | Quick Controls, target window selection |
| v1.5 | âœ… Released | Text Editor tab, YouTube/URL, PDF/DOCX, editable results |
| **v1.6** | ğŸš§ In Progress | Enhanced UX, chat tab, dictation mode |
| v2.0 | ğŸ“‹ Planned | See below â†“ |

---

## Coming Soon

> We are working on a significant upgrade. Here is what is on the horizon â€” without giving away the implementation details.

### ğŸ¯ Smarter Context Awareness
Future versions will understand **what you are working on** and tailor their output accordingly â€” without you having to switch templates manually. Imagine the system knowing whether you are writing code, composing an email, or drafting a report, and adjusting its output format automatically.

### ğŸ”— Deeper Tool Integration
We are building **native integrations** that go beyond the current WebSocket bridge. Think direct plugin hooks for popular developer tools â€” not just "type text", but full two-way awareness of what the tool knows and needs.

### ğŸŒ Multi-Language Intelligence
Beyond basic transcription in multiple languages: understanding **code-switching** (mixing languages mid-sentence), technical vocabulary in non-English languages, and automatic language detection per session.

### ğŸ§  Persistent Session Memory
A future version will maintain awareness of your **ongoing work sessions** â€” so when you come back to a project after a break, the system picks up context without you having to re-explain.

### ğŸ“Š Structured Data Extraction
Speech-to-structured-data: dictate naturally and have the system extract **tables, action items, decisions, dates** and export them in structured formats (JSON, CSV, calendar events) â€” not just clean text.

### âš¡ Real-Time Collaboration
Early-stage research into **multi-user voice sessions** â€” where multiple people can speak into a shared session, with speaker identification and automatic meeting minutes generation.

---

## Contributing

Issues and pull requests are welcome. Please read the project `CLAUDE.md` before contributing to understand the architecture and coding conventions.

---

## License

MIT â€” free for personal and commercial use.

---

<p align="center">
  Built with â¤ï¸ by the <strong>BACON-AI</strong> team
</p>
