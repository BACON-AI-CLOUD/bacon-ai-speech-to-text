# ADD-003: BACON-AI Voice v1.3 - UX Enhancements Architecture

**Version:** 1.3
**Status:** Draft
**Date:** 2026-02-20
**Parent:** ADD-002 (v1.1 Architecture)
**PRD:** PRD-003 (v1.3 UX Enhancements)

---

## 1. Feature Overview

v1.3 adds major UX improvements and new interaction modes:
1. **Right Sidebar Quick Controls** - Collapsible panel for provider/model/template + output controls
2. **Audio Beeps for All Modes** - Web Audio API beeps on all activation modes
3. **Chat Tab** - Chatbot UI connected to text refinement (voice + text input)
4. **Dictation Mode** - Continuous long-form dictation with pause/resume canvas
5. **MCP Server** - Text refinement engine exposed as MCP tools
6. **Wake Word** - "Hey Colin" hands-free trigger (configurable)
7. **Mini-Button Collapse** - Floating widget mode
8. **History Persistence + Projects** - IndexedDB storage, project grouping

### Design Goals
1. **Zero friction**: Most-used controls always one click away
2. **Non-destructive**: All new features additive, existing STT flow unchanged
3. **Offline-first**: History stored locally (IndexedDB), no backend dependency
4. **Progressive disclosure**: Advanced features hidden until needed

---

## 2. Layout Architecture (v1.3 Delta)

### Current Layout (v1.2)
```
┌─────────────────────────────────────────┐
│ Header                                  │
├──────────┬──────────────────────────────┤
│ History  │  Mic + Controls              │
│ Sidebar  │  Latest Transcription        │
│ (280px)  │  Settings (gear icon)        │
│          │                              │
└──────────┴──────────────────────────────┘
```

### Target Layout (v1.3)
```
┌─────────────────────────────────────────────────────┐
│ Header                           [Tab: STT|Chat|Dict]│
├──────────┬──────────────────────────────┬────────────┤
│ History  │  [Active Tab Content]        │  Quick     │
│ Sidebar  │                              │  Controls  │
│ (240px)  │  STT: Mic + transcription   │  Sidebar   │
│ scrolls  │  Chat: Bubble conversation  │  (220px)   │
│ projects │  Dict: Canvas accumulator   │  collapses │
│          │                              │            │
└──────────┴──────────────────────────────┴────────────┘
```

### Layout Components
- **Left sidebar** (existing, expanded): History + projects
- **Center**: Tab switcher (STT | Chat | Dictation)
- **Right sidebar** (new): Quick controls panel (collapsible)
- **Footer**: Status bar (unchanged)

---

## 3. Component Architecture

### 3.1 New Frontend Components

```
src/frontend/src/components/
├── QuickControlsSidebar.tsx     # Right sidebar (REQ-301, 302)
├── QuickControlsSidebar.css
├── ChatTab.tsx                  # Chat interface (REQ-304-306)
├── ChatTab.css
├── DictationTab.tsx             # Dictation canvas (REQ-307-310)
├── DictationTab.css
├── TabSwitcher.tsx              # STT | Chat | Dictation tabs
├── TabSwitcher.css
├── MiniButton.tsx               # Collapsed floating widget (REQ-315-316)
├── MiniButton.css
└── ProjectSelector.tsx          # Project grouping UI (REQ-319-320)
    ProjectSelector.css
```

### 3.2 New Hooks

```
src/frontend/src/hooks/
├── useHistory.ts                # IndexedDB history CRUD + projects
├── useDictation.ts              # Dictation state machine
└── useWakeWord.ts               # Wake word detection (Phase F)
```

### 3.3 Modified Components

| Component | Change |
|-----------|--------|
| `App.tsx` | Add tab state, right sidebar toggle, mini-button mode |
| `App.css` | Three-column layout (left sidebar + center + right sidebar) |
| `HistorySidebar.tsx` | Add project grouping, persistent history from IndexedDB |
| `HistorySidebar.css` | Project accordion sections |

---

## 4. Data Architecture

### 4.1 IndexedDB Schema (useHistory.ts)

```typescript
// Database: bacon-ai-voice
// Version: 1

// Object Store: projects
interface Project {
  id: string;          // uuid
  name: string;
  color: string;       // hex color for label
  createdAt: number;   // timestamp
}

// Object Store: history
interface HistoryEntry {
  id: string;          // uuid
  projectId: string | null;
  source: 'stt' | 'chat' | 'dictation';
  text: string;        // raw transcription or chat message
  refinedText?: string;
  provider?: string;
  model?: string;
  template?: string;
  confidence?: number;
  timestamp: number;
  // For dictation entries
  segments?: string[];
  // For chat entries
  role?: 'user' | 'assistant';
  sessionId?: string;  // group chat messages by session
}

// Indexes:
// history.timestamp (for sorting)
// history.projectId (for filtering)
// history.source (for filtering)
// history.sessionId (for chat grouping)
```

### 4.2 State Management

New app-level state in `App.tsx`:
```typescript
// Tab navigation
const [activeTab, setActiveTab] = useState<'stt' | 'chat' | 'dictation'>('stt');

// Right sidebar
const [quickControlsOpen, setQuickControlsOpen] = useState(true);

// Mini-button mode
const [miniMode, setMiniMode] = useState(false);

// Chat conversation history (in-memory, persisted to IndexedDB per session)
const [chatHistory, setChatHistory] = useState<ChatMessage[]>([]);
const [chatSessionId] = useState(() => crypto.randomUUID());

// Dictation canvas
const [dictationSegments, setDictationSegments] = useState<string[]>([]);
const [dictationSessionId] = useState(() => crypto.randomUUID());
```

---

## 5. Phase Implementation Plans

### Phase A: Right Sidebar + Audio Beeps

**Files:**
- NEW: `QuickControlsSidebar.tsx` / `.css`
- EDIT: `App.tsx` - add right sidebar toggle state
- EDIT: `App.css` - three-column layout

**QuickControlsSidebar props:**
```typescript
interface QuickControlsSidebarProps {
  settings: AppSettings;
  onSettingsChange: (settings: AppSettings) => void;
  providers: ProviderInfo[];
  models: ModelInfo[];
  isOpen: boolean;
  onToggle: () => void;
}
```

**Tabs inside sidebar:**
- **Refinement tab**: provider dropdown, model dropdown, template dropdown, enable toggle
- **Output tab**: send-to checkboxes, target window input

**Audio beeps (currently only on REST API connection):**
- Move beep logic from backend-triggered to frontend state-driven
- Trigger on: `recordingState` transitions in `useActivation`
- `idle -> recording`: ascending beep (existing beepFreqStart)
- `recording -> processing`: descending beep (micOffBeepFreq)
- `processing -> idle` (with result): double beep

### Phase B: Chat Tab

**Files:**
- NEW: `ChatTab.tsx` / `.css`
- EDIT: `App.tsx` - wire chat history state
- EDIT: `TabSwitcher.tsx` - new component for tab switching

**ChatTab behavior:**
- Messages display in bubble format (user right, AI left)
- Mic button: captures speech via WebSocket -> transcribes -> sends as user message
- Text input: type/paste -> Enter or Send button
- Calls `POST /discuss/chat` with full `history` array for context
- Response plays audio + shows text bubble
- "New Chat" button: saves session to IndexedDB, clears state

**Message flow:**
```
User speaks/types
    -> [if voice] WebSocket transcription
    -> setChatHistory([...prev, {role:'user', content}])
    -> POST /discuss/chat { text, history, voice }
    -> setChatHistory([...prev, {role:'assistant', content: data.answer}])
    -> Play audio (data.audio_url)
    -> Save to IndexedDB
```

### Phase C: Dictation Mode

**Files:**
- NEW: `DictationTab.tsx` / `.css`
- NEW: `useDictation.ts`

**useDictation state machine:**
```
IDLE -> LISTENING (user activates)
LISTENING -> SEGMENT_PROCESSING (silence detected after speech)
SEGMENT_PROCESSING -> LISTENING (auto-resume)
LISTENING -> PAUSED (long silence > 10s or user pauses)
PAUSED -> LISTENING (user speaks again)
any -> IDLE (user clicks Stop)
```

**DictationTab UI:**
```
┌─────────────────────────────────────────┐
│ DICTATION CANVAS              [New][Stop]│
├─────────────────────────────────────────┤
│ [Refined segment 1...]                  │
│ [Refined segment 2...]                  │
│ [Currently processing... |||]           │
│                                         │
└─────────────────────────────────────────┘
│ [Pause] [Copy All] [Download .md]       │
└─────────────────────────────────────────┘
```

**Key behaviors:**
- Each segment: one WebSocket transcription cycle
- Segment immediately sent to refiner (parallel while next recording starts)
- Canvas shows refined segments in order, with "processing" spinner for current
- "New Chat" -> saves all segments as one HistoryEntry -> clears canvas

### Phase D: History Persistence + Projects

**Files:**
- NEW: `useHistory.ts` - IndexedDB wrapper
- NEW: `ProjectSelector.tsx` / `.css`
- EDIT: `HistorySidebar.tsx` - use IndexedDB instead of in-memory

**useHistory API:**
```typescript
const {
  entries,          // HistoryEntry[]
  projects,         // Project[]
  addEntry,         // (entry) => Promise<void>
  deleteEntry,      // (id) => Promise<void>
  createProject,    // (name, color) => Promise<Project>
  deleteProject,    // (id) => Promise<void>
  assignProject,    // (entryId, projectId) => Promise<void>
  activeProject,    // string | null
  setActiveProject, // (id | null) => void
} = useHistory();
```

**Migration:** On first load, if localStorage has history entries, migrate to IndexedDB.

### Phase E: MCP Server

**Files:**
- NEW: `src/mcp-server/` directory
  - `server.py` - MCP server (stdio transport)
  - `refiner_client.py` - HTTP client calling localhost:8702/refiner/*
  - `pyproject.toml`

**MCP Tools:**
```python
@server.tool("refine_text")
async def refine_text(text: str, provider: str | None = None,
                      model: str | None = None, template: str | None = None):
    """Refine raw text using the configured AI provider."""

@server.tool("get_refiner_config")
async def get_refiner_config():
    """Get current provider, model, and template configuration."""

@server.tool("set_refiner_config")
async def set_refiner_config(provider: str | None = None,
                              model: str | None = None,
                              template: str | None = None):
    """Update the active refiner configuration."""
```

**Communication:** MCP server calls `localhost:8702` (existing FastAPI). No shared state - thin HTTP client wrapper.

### Phase F: Wake Word + Mini-Button

**Wake Word (REQ-313-314):**
- Technology: Web Speech API `SpeechRecognition` with keyword matching (browser-native, no downloads)
- Fallback: Continuous Whisper polling (CPU intensive, last resort)
- Config: `wakeWord: string` in AppSettings (default: "hey colin")
- Flow: `SpeechRecognition.continuous = true` -> match transcript -> trigger STT

**Mini-Button (REQ-315-316):**
- CSS: `position: fixed; bottom: 20px; right: 20px; width: 56px; height: 56px`
- `miniMode = true`: hide header, sidebars, show only mic button + status dot
- `window.resizeTo(80, 80)` attempted, graceful fallback to CSS-only
- Hover: show last transcription in tooltip

---

## 6. Backend Changes

### 6.1 No Changes Required for Phase A-D
The existing FastAPI backend (ports 8702) fully supports v1.3 frontend changes:
- `/refiner/*` endpoints: all provider/model switching
- `/discuss/chat`: chat with history
- WebSocket: STT for dictation segments and chat voice input

### 6.2 New: MCP Server (Phase E)
- Standalone Python process, separate from FastAPI
- Default port: stdio (MCP standard)
- Reads config from same `.env` file via `dotenv_values`

---

## 7. Non-Functional Requirements

| NFR | Target | Notes |
|-----|--------|-------|
| Right sidebar animation | 200ms CSS transition | Slide in/out |
| IndexedDB write latency | <10ms | Async, non-blocking |
| Chat message render | <50ms | After API response received |
| Dictation segment gap | <500ms | Time between stop + restart |
| History load on startup | <200ms | IndexedDB read |
| Wake word CPU usage | <5% idle | SpeechRecognition API |
| MCP server response | <backend latency + 10ms | Thin wrapper |

---

## 8. Migration Notes

### localStorage -> IndexedDB History
- On first v1.3 load, check localStorage for existing history entries
- Migrate to IndexedDB as source "stt" with projectId null
- Keep localStorage settings (they stay in localStorage)

### Beep System
- Existing REST-API beep (countdown before recording) stays unchanged
- New: state-change beeps added to activation mode transitions
- Both systems coexist, controlled by same beep settings

---

*ADD-003 created 2026-02-20. Status: Draft. Awaiting implementation.*
